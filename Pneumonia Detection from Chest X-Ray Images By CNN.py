# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Z29-qkG-uE-EuRmQopuAiysdYwDeg7E3
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns
import os
import zipfile
import shutil

!pip install kaggle

from google.colab import files
print("Please upload your 'kaggle.json' file now:")
files.upload()

!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json # Set permissions

print("Kaggle API setup complete. Proceeding to download Chest X-Ray dataset.")

!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia

zip_file_path = 'chest-xray-pneumonia.zip'
extract_dir = 'chest_xray_dataset' # Directory to extract the contents

os.makedirs(extract_dir, exist_ok=True)

print(f"Unzipping {zip_file_path} to {extract_dir}...")
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extract_dir)
print("Dataset unzipped successfully!")

main_data_dir = os.path.join(extract_dir, 'chest_xray')
if not os.path.exists(main_data_dir):
    if os.path.exists(os.path.join(extract_dir, 'train')):
        main_data_dir = extract_dir
    else:
        print(f"Error: Could not find main data directory (e.g., '{main_data_dir}'). Please inspect {extract_dir}")
        !ls -R {extract_dir} # Show recursive listing to help debug
        exit()

train_dir = os.path.join(main_data_dir, 'train')
val_dir = os.path.join(main_data_dir, 'val')
test_dir = os.path.join(main_data_dir, 'test')

print(f"\nVerifying dataset structure:")
print(f"Train directory exists: {os.path.exists(train_dir)}")
print(f"Validation directory exists: {os.path.exists(val_dir)}")
print(f"Test directory exists: {os.path.exists(test_dir)}")

def count_files_in_subfolders(parent_dir, subfolder_names=['NORMAL', 'PNEUMONIA']):
    counts = {}
    for subfolder in subfolder_names:
        path = os.path.join(parent_dir, subfolder)
        if os.path.exists(path):
            counts[subfolder] = len(os.listdir(path))
        else:
            counts[subfolder] = 0
    return counts

print("\n--- Dataset Distribution ---")
train_counts = count_files_in_subfolders(train_dir)
val_counts = count_files_in_subfolders(val_dir)
test_counts = count_files_in_subfolders(test_dir)

print(f"Train set: {train_counts}")
print(f"Validation set: {val_counts}")
print(f"Test set: {test_counts}")

labels = ['NORMAL', 'PNEUMONIA']
train_sizes = [train_counts['NORMAL'], train_counts['PNEUMONIA']]
val_sizes = [val_counts['NORMAL'], val_counts['PNEUMONIA']]
test_sizes = [test_counts['NORMAL'], test_counts['PNEUMONIA']]

x = np.arange(len(labels))
width = 0.25

fig, ax = plt.subplots(figsize=(10, 6))
rects1 = ax.bar(x - width, train_sizes, width, label='Train')
rects2 = ax.bar(x, val_sizes, width, label='Validation')
rects3 = ax.bar(x + width, test_sizes, width, label='Test')

ax.set_ylabel('Number of Images')
ax.set_title('Distribution of NORMAL vs. PNEUMONIA Classes across Subsets')
ax.set_xticks(x)
ax.set_xticklabels(labels)
ax.legend()
plt.show()

IMG_HEIGHT = 48
IMG_WIDTH = 48
BATCH_SIZE = 64

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.1,
    zoom_range=0.1,
    horizontal_flip=True,
    fill_mode='nearest'
)

val_test_datagen = ImageDataGenerator(rescale=1./255)

print("Training images")
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE,
    class_mode='binary',
    color_mode='rgb'
)

print("Validation images")
validation_generator = val_test_datagen.flow_from_directory(
    val_dir,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE,
    class_mode='binary',
    color_mode='rgb'
)

print("Test images")
test_generator = val_test_datagen.flow_from_directory(
    test_dir,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE,
    class_mode='binary',
    color_mode='rgb',
    shuffle=False
)

class_names = list(train_generator.class_indices.keys())
print(f"Detected classes: {class_names}")
print(f"Class indices: {train_generator.class_indices}")

model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 3)),
    MaxPooling2D((2, 2)),
    Dropout(0.25),

    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Dropout(0.25),

    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Dropout(0.25),

    Conv2D(256, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Dropout(0.25),

    Flatten(),

    Dense(512, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer= Adam(learning_rate=0.00001),
              loss='binary_crossentropy',
              metrics=['accuracy'])
model.summary()

"""IMG_HEIGHT = 48
IMG_WIDTH = 48
batch_size = 64

train_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2
)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    color_mode='grayscale',
    batch_size=batch_size,
    class_mode='binary',
    shuffle=True
)

val_generator = val_datagen.flow_from_directory(
    val_dir,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    color_mode='grayscale',
    batch_size=batch_size,
    class_mode='binary',
    shuffle=False
)

model.compile(optimizer=Adam(learning_rate=0.0001),
              loss='binary_crossentropy',
              metrics=['accuracy'])

early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss', patience=5, restore_best_weights=True, verbose=1
)

history = model.fit(
    train_generator,
    validation_data=validation_generator,
    epochs = 50,
    callbacks=[early_stopping, reduce_lr],
    verbose=1
)

plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()

loss, accuracy = model.evaluate(test_generator, verbose=0)
print(f"Test Loss: {loss:.4f}")
print(f"Test Accuracy: {accuracy:.4f}")

test_generator.reset()
y_pred_probs = model.predict(test_generator)
y_pred_classes = (y_pred_probs > 0.5).astype(int).flatten()

y_true = test_generator.classes[test_generator.index_array]

cm = confusion_matrix(y_true, y_pred_classes)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

print("\n--- Classification Report ---")
print(classification_report(y_true, y_pred_classes, target_names=class_names))

num_samples_to_display = 10

test_generator.reset()
test_image_paths = test_generator.filepaths
test_true_labels = test_generator.classes

random_indices = np.random.choice(len(test_image_paths), num_samples_to_display, replace=False)

plt.figure(figsize=(15, 12))
for i, idx in enumerate(random_indices):
    img_path = test_image_paths[idx]
    true_label_id = test_true_labels[idx]

    img = tf.keras.utils.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH), color_mode='rgb')
    img_array = tf.keras.utils.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array = img_array / 255.0

    prediction_prob = model.predict(img_array, verbose=0)[0][0]
    predicted_label_id = 1 if prediction_prob > 0.5 else 0

    true_label_name = class_names[true_label_id]
    predicted_label_name = class_names[predicted_label_id]

    plt.subplot(2, 5, i + 1)
    plt.imshow(img)
    plt.title(f"True: {true_label_name}\nPred: {predicted_label_name} ({prediction_prob:.2f})",
              color='green' if true_label_id == predicted_label_id else 'red')
    plt.axis('off')
plt.tight_layout()
plt.show()